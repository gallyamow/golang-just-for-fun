package funbytes

import (
	"bytes"
	"io"
)

// Buffer предназначен для эффективной работы с буферами байт.
//
// Для чего:
// 1) Не нужно вручную выделять или увеличивать массив — буфер сам растёт по мере необходимости.
// 2) Очень быстрый: минимизирует копирование памяти.
// 3) Удобен для сборки строк или двоичных данных. Часто используется при генерации данных в памяти (например,
// JSON, HTTP-запросы, логирование и т.п.).
//
// Как с ним работать:
// 1) Ненулевой не стоит копировать. У него нет _noCopy - потому что нулевой все же можно копировать. Копировать
// его нельзя, потому что внутри срез байтов. Копии будут указывать на тот же underlying array и смещения off у них разные.
// Копировать надо копируя срез байт в новый buffer.
//
// Как реализован:
// Внутри buf []byte, off - offset чтения, lastRead - тип последней операции (используется для правильного чтения rune)
// Буфером по сути является место с off до len(buf) = m.
// При операции чтения:
// 1) читает с off до заполнения data, либо пока есть данные. Если данных вообще нет - EOF.
// 2) ничего не делает с прочитанными данными
// При записи: добавляет в конец среза.
// Может оказаться что не хватает места, тогда:
// m = len(b.buf) - b.off
// 1) если свободный размер буфера 0 - то есть новых данных нет, а off не 0 - то есть уже читали и сместили - значит
// буфер можно переиспользовать, поэтому обнуляет off и заново будет читать с начала среза.
// 2) если capacity среза позволяет увеличить len до n - делает. Делает он это не путем append(), а сначала увеличивает
// размер массива через b.buf = b.buf[:l+n], а потом пишет данные через copy (скорее всего связано с тем что функция
// используется в нескольких местах, а не только во Write).
// 3) если буфер nil и пишут немного (n < smallBufferSize = 64), то делает аллокацию размером smallBufferSize элемента.
// Тут расчет на то что чтобы не выделять много места сразу
// 4) так как при чтении мы просто перемещаем off, то позади него скапливается уже прочитанное, значит мы можем просто
// занулить off и скопировать данные в начало slice
// 5) крайний вариант делает 2x (исторически так сложилось, в будущем будут реагировать на темп роста), специально
// делает его так append([]byte(nil), make([]byte, c)...) - добавляет данные к новому nil-slice,
// вместо append(b, make([]byte, n)...) текущий. Пишут чтобы не "убегала в кучу".
// При этому получается что с начала массива будут нули, поэтому приходится копировать содержимое туда.
//
// Моя реализация реализует только часть методов, например нет поддержки rune (нет lastRead), truncate, string.
type Buffer struct {
	buf    []byte
	offset int
}

// Bytes возвращает срез байт длиной b.Len() хранящийся в непрочитанной части буфера.
func (b *Buffer) Bytes() []byte {
	return b.buf[b.offset:]
}

// Len возвращает количество байт в непрочитанной части буфера.
func (b *Buffer) Len() int {
	return len(b.buf) - b.offset
}

// Cap возвращает емкость underlying среза, что является, количеством выделенной памяти.
func (b *Buffer) Cap() int {
	return cap(b.buf)
}

// Available возвращает сколько байт не использованы в буфере.
func (b *Buffer) Available() int {
	return cap(b.buf) - len(b.buf)
}

// AvailableBuffer возвращает пустой срез байт емкостью b.Available(), то есть количеству байт, которое можно записать
// без перераспределения памяти.
// Этот срез предназначен последующей записи через buffer.Write().
// Этот срез валиден только до следующей записи в b.
// Смысл: если есть буфер с достаточной ёмкостью, можно напрямую писать в его срез и потом "сообщить" буферу, что данные добавлены.
func (b *Buffer) AvailableBuffer() []byte {
	return b.buf[len(b.buf):]
}

// Reset сбрасывает буфер, сохраняет underlying хранилище для последующих записей.
func (b *Buffer) Reset() {
	b.offset = 0
	b.buf = b.buf[:0]
}

// @idiomatic: maximum int value
// uint(0) = для uint64 => 0x0000....0000 => ^uint(0) = 0x1111....1111
// сдвигаем вправо для освобождения знакового бита (так как int знаковый, если этого не сделать - то получим -1,
// так как 0x1111....1111 - в доп. коде это -1)
// p.s. Используется two’s complement (все современные процессоры используют two’s complement для представления int).
// Основное его преимущество - вычитание выглядит как сложение.
// Пример:
// 0000 0001 = 1, 1111 1111 = -1 => 1+-1 = 0 => 0000 0001 + 1111 1111 = 0000 0000 (перенос отбрасывается).
// Получить его можно так: 1) Инвертируешь все биты (заменяешь 0 на 1, и наоборот) 2) Прибавляешь 1
// => ^uint(0) >> 1) = 0x0101....0101
// Другие схемы: 1) знак+модуль (+/- отдельно) 2) обратный код (one’s complement) имеют след. проблемы:
// - два представления нуля (+0 и -0)
// - сложение и вычитание требовали отдельных правил
const maxInt = int(^uint(0) >> 1)

// Write пишет данные из p в буфер, увеличивая его если необходимо.
// Возвращаемое значение n равно длине p, err всегда nil.
// Вызов всегда успешный за исключением превышения размера буфера (maxInt), в там случае паникует с [ErrTooLarge].
// @idiomatic: overflow-safe arithmetic
func (b *Buffer) Write(p []byte) (int, error) {
	c := cap(b.buf)
	n := len(p)

	// Первое использование
	// В реальной реализации используется константа 64
	if b.buf == nil {
		b.buf = make([]byte, 0, n)
	}

	// места хватает в capacity
	avail := b.Available()
	if n <= avail {
		b.buf = append(b.buf, p...)
		return n, nil
	}

	// Если количество непрочитанных + количество добавляемых помещается в cap, тогда, копируем данные в начало массива
	// и зануляем offset. Что дает нам возможность повторно использовать первые элементы.
	// Условие на самом деле такое (b.Len()+n <= c) и преобразовано согласно overflow-safe arithmetic в b.Len() <= c-n)
	// ([1,2,3,4*,5,6,7,8] + 3) => (5 + 3 <= 8) => ([4*,5,6,7,8,0,0,0])
	// В реальной реализации сравнивают с "c/2" чтобы добиться 2x grow уже при b.Len()+n <= c/2.
	// В своей оставлю именно так, чтобы на benchmarks увидеть разницу.
	if b.Len() <= c-n {
		b.offset = 0
		copy(b.buf, b.buf[b.offset:])
		// вместо append используем копирование, которое перезапишет данные (для append надо сначала урезать массив)
		copy(b.buf[b.offset:], p)

		// урезаем полученный slice (это позволяет игнорировать значения вне рамок)
		size := b.offset + n
		b.buf = b.buf[:size]

		return n, nil
	}

	// Собираемся сделать 2x grow, надо проверить что не выходим за рамки maxInt.
	// Это выражение математически эквивалентно 2*c+n > maxInt, но в отличие от него не вызывает переполнение
	// в случае близких к maxInt значения. Здесь используем 2x потому что планируем в 2 раза увеличить.
	// Такое преобразование легко сделать, просто вместо сложения делая вычитание на другой стороне уравнения:
	// a+b+c < d+e+f => a-e-f < d-b-c
	// @idiomatic: overflow-safe arithmetic
	if c > maxInt-c-n {
		panic(bytes.ErrTooLarge)
	}

	b.buf = append(b.buf, make([]byte, 2*c-b.Len())...)
	copy(b.buf[b.offset:], p)

	// урезаем полученный slice (это позволяет игнорировать значения вне рамок)
	size := b.offset + n
	b.buf = b.buf[:size]

	return n, nil
}

// Read читает следующие len(p) байты из буфера до тех пор, пока буфер не будет исчерпан.
// Возвращаемое значение n количество прочитанных байтов.
// Если буфер не содержит данных то, err будет [io.EOF] только если len(p) не равно нулю, иначе nil.
func (b *Buffer) Read(p []byte) (int, error) {
	// Нет непрочитанных данных
	if b.Len() == 0 {
		// Сбрасываем буфер, чтобы переиспользовать его
		b.Reset()

		// Согласно контакту, если len(p) равно нулю, то возвращаем EOF
		if len(p) != 0 {
			return 0, io.EOF
		}

		return 0, nil
	}

	n := copy(p, b.buf[b.offset:])
	b.offset += n

	return n, nil
}
